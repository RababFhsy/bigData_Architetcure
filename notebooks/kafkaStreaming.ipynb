{
  "metadata": {
    "name": "kafkaStreaming",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport subprocess\n\n# Packages to install\npackages_to_install \u003d [\u0027kafka-python\u0027, \u0027ntscraper\u0027]\n\n# Use subprocess to run the pip install commands\nfor package in packages_to_install:\n    subprocess.call([\u0027pip\u0027, \u0027install\u0027, package])\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\r\nimport json\r\nfrom kafka import KafkaProducer\r\nfrom ntscraper import Nitter\r\n\r\n# Define the Kafka Producer configuration\r\nKAFKA_BOOTSTRAP_SERVERS \u003d [\u0027kafka-broker:29092\u0027]\r\nKAFKA_TOPIC_NAME \u003d \u0027sentiment_analysis\u0027\r\nKAFKA_PRODUCER_CONFIG \u003d {\r\n    \u0027bootstrap_servers\u0027: KAFKA_BOOTSTRAP_SERVERS\r\n}\r\n\r\nterms \u003d [\"genocide\", \"gaza\", \"world\"]\r\ncontinents \u003d [\"France\", \"Morocco\", \"Austria\", \"Belgium\", \"Italy\"]\r\n\r\ndef get_twitter_data(terms, continents):\r\n    Twitter_data_list \u003d []\r\n    scraper \u003d Nitter(0)  # Initialize the Nitter scraper\r\n\r\n    for term in terms:\r\n        for country in continents:\r\n            # Fetch tweets using the Nitter scraper\r\n            tweets \u003d scraper.get_tweets(term, mode\u003d\u0027term\u0027, language\u003d\u0027en\u0027, number\u003d100, near\u003dcountry)\r\n            \r\n            # Print information about the tweets variable (optional, for debugging)\r\n            # print(f\"Term: {term}, Country: {country}, Tweets: {tweets}\")\r\n            \r\n            for x in tweets[\u0027tweets\u0027]:\r\n                # Extract relevant information from each tweet and structure it in a dictionary\r\n                data \u003d {\r\n                    \u0027text\u0027: x[\u0027text\u0027],\r\n                    \u0027date\u0027: x[\u0027date\u0027],\r\n                    \u0027likes\u0027: x[\u0027stats\u0027][\u0027likes\u0027],\r\n                    \u0027is_retweet\u0027: x[\u0027is-retweet\u0027],  # Assuming it\u0027s a boolean indicating if it\u0027s a retweet\r\n                    \u0027retweets\u0027: x[\u0027stats\u0027][\u0027retweets\u0027],\r\n                    \u0027country\u0027: country  # Add the country name to the data\r\n                }\r\n                Twitter_data_list.append(data)\r\n\r\n    return Twitter_data_list\r\n\r\ndef main(terms):\r\n    try:\r\n        # Initialize Kafka producer\r\n        producer \u003d KafkaProducer(**KAFKA_PRODUCER_CONFIG)\r\n\r\n        # Fetch Twitter data using the defined terms and continents\r\n        twitter_data \u003d get_twitter_data(terms, continents)\r\n\r\n        # Send each tweet as a JSON-encoded message to the Kafka topic\r\n        for tweet in twitter_data:\r\n            json_data \u003d json.dumps(tweet)  # Convert the data to a JSON string\r\n            print(json_data)  # Print the JSON data (optional, for debugging)\r\n            producer.send(KAFKA_TOPIC_NAME, json_data.encode())  # Send JSON data to Kafka topic\r\n\r\n    except Exception as e:\r\n        # Handle exceptions and print errors if any\r\n        print(f\u0027Error: {e}\u0027)\r\n\r\n# Execute the main function with the specified search terms\r\nmain(terms)\r\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n"
    }
  ]
}