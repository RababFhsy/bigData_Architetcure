{
  "metadata": {
    "name": "streaming",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import from_json, col\nfrom pyspark.sql.types import StructType, StructField, StringType, DoubleType, BooleanType, LongType\n\n# Create a SparkSession\nspark \u003d SparkSession.builder \\\n    .appName(\"sentiment_analysis_read\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\n# Kafka details\nkafka_server \u003d \"kafka-broker:29092\"\ntopic \u003d \"sentiment_analysis\"\n\n# Define the schema to match your data\nschema \u003d StructType([\n    StructField(\"text\", StringType()),\n    StructField(\"date\", StringType()),\n    StructField(\"likes\", DoubleType()),\n    StructField(\"is_retweet\", BooleanType()),\n    StructField(\"retweets\", LongType()),\n    StructField(\"country\", StringType()),\n])\n\n# Read data from Kafka\ndf \u003d spark.readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_server) \\\n    .option(\"subscribe\", topic) \\\n    .load() \\\n    .selectExpr(\"CAST(value AS STRING)\") \\\n    .select(from_json(\"value\", schema).alias(\"data\")) \\\n    .select(\"data.*\")\n\n# Write data to a Parquet format\nquery \u003d df.writeStream \\\n    .outputMode(\"append\") \\\n    .format(\"parquet\") \\\n    .option(\"path\", \"/user/hive/warehouse/datatest1\") \\\n    .option(\"checkpointLocation\", \"/tmp3/check3\") \\\n    .start() \n\n# Await termination to keep the stream running\nquery.awaitTermination()\n\n# Stop the Spark session\nspark.stop()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\n"
    }
  ]
}